{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibj3h8UjpBo_"
      },
      "source": [
        "**1. Leer el archivo CO2 emissions.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23ZR1Z2Iohol",
        "outputId": "76183e1e-980c-48bc-da80-f08865a523cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ENGINESIZE  CYLINDERS  FUELCONSUMPTION_CITY  FUELCONSUMPTION_HWY  \\\n",
            "0         2.0          4                   9.9                  6.7   \n",
            "1         2.4          4                  11.2                  7.7   \n",
            "2         1.5          4                   6.0                  5.8   \n",
            "3         3.5          6                  12.7                  9.1   \n",
            "4         3.5          6                  12.1                  8.7   \n",
            "\n",
            "   CO2EMISSIONS  \n",
            "0             0  \n",
            "1             0  \n",
            "2             0  \n",
            "3             0  \n",
            "4             0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # Importamos la biblioteca pandas y la abreviamos como pd para facilitar su uso.\n",
        "\n",
        "# Leer el archivo CSV\n",
        "# Utilizamos la función read_csv de pandas para leer el archivo 'CO2 emissions.csv' y cargarlo en un DataFrame llamado 'df'.\n",
        "df = pd.read_csv('CO2 emissions.csv')\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "# Utilizamos el método head() del DataFrame para imprimir las primeras cinco filas del DataFrame, lo que nos da una vista previa de los datos.\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2J_W5Z3pJvO"
      },
      "source": [
        "**2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "83fILXvOpPyt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split  # Importamos la función train_test_split de sklearn para dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "# Separar variables independientes y dependientes\n",
        "# Aquí seleccionamos las columnas 'ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_CITY' y 'FUELCONSUMPTION_HWY' como variables independientes (X).\n",
        "# La columna 'CO2EMISSIONS' es nuestra variable dependiente (y) que queremos predecir.\n",
        "X = df[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_CITY', 'FUELCONSUMPTION_HWY']]\n",
        "y = df['CO2EMISSIONS']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "# Utilizamos la función train_test_split para dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%).\n",
        "# El parámetro random_state=123 asegura que la división sea reproducible.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gesdCGypb4N"
      },
      "source": [
        "**3. Utilizar una estrategia para normalizar los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PggjeZIQph6Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler  # Importamos la clase StandardScaler de sklearn para estandarizar las variables.\n",
        "\n",
        "# Estandarizar las variables\n",
        "# Creamos una instancia de StandardScaler, que estandariza los datos restando la media y dividiendo por la desviación estándar.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustamos el scaler a los datos de entrenamiento y transformamos X_train\n",
        "# fit_transform ajusta el scaler a los datos de entrenamiento y luego los transforma.\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transformamos X_test utilizando el mismo scaler ajustado con X_train\n",
        "# transform aplica la misma transformación a los datos de prueba sin volver a ajustar el scaler.\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MyrGmj4pkpV"
      },
      "source": [
        "**4. Configurar los hiperparámetros del árbol de decisión y obtener 10 árboles variando max_depth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARzAXgsvpoKd",
        "outputId": "84036fab-6efe-453d-f290-c9e9ac28f038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   max_depth  accuracy\n",
            "0          1  0.948598\n",
            "1          2  0.943925\n",
            "2          3  0.943925\n",
            "3          4  0.939252\n",
            "4          5  0.962617\n",
            "5          6  0.953271\n",
            "6          7  0.953271\n",
            "7          8  0.957944\n",
            "8          9  0.957944\n",
            "9         10  0.957944\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier  # Importamos la clase DecisionTreeClassifier de sklearn para crear árboles de decisión.\n",
        "from sklearn.metrics import accuracy_score  # Importamos accuracy_score para evaluar la precisión del modelo.\n",
        "import pandas as pd  # Importamos pandas para trabajar con DataFrames.\n",
        "\n",
        "# Función para entrenar y evaluar árboles de decisión\n",
        "def evaluate_decision_trees(criterion, splitter, max_depth_values, random_state=123):\n",
        "    results = []  # Lista para almacenar los resultados\n",
        "    for max_depth in max_depth_values:\n",
        "        # Creamos un clasificador de árbol de decisión con los parámetros dados\n",
        "        clf = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, random_state=random_state)\n",
        "        clf.fit(X_train, y_train)  # Entrenamos el clasificador con los datos de entrenamiento\n",
        "        y_pred = clf.predict(X_test)  # Realizamos predicciones sobre los datos de prueba\n",
        "        accuracy = accuracy_score(y_test, y_pred)  # Calculamos la precisión del modelo\n",
        "        # Almacenamos los resultados en la lista results\n",
        "        results.append({'max_depth': max_depth, 'accuracy': accuracy})\n",
        "    # Convertimos la lista de resultados en un DataFrame y lo devolvemos\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Evaluar árboles de decisión con criterion='gini', splitter='best'\n",
        "max_depth_values = range(1, 11)  # Valores de profundidad máxima del árbol a probar\n",
        "results_gini_best = evaluate_decision_trees('gini', 'best', max_depth_values)  # Evaluamos los árboles de decisión\n",
        "print(results_gini_best)  # Imprimimos los resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-sUu6NxpwWr"
      },
      "source": [
        "**5. Incluir una tabla con el accuracy para los 10 árboles del punto anterior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-2PfFOqpzoE",
        "outputId": "446b9d25-f905-4154-cff7-cc9ab3a6e5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para criterion='gini' y splitter='best':\n",
            "   max_depth  accuracy\n",
            "0          1  0.948598\n",
            "1          2  0.943925\n",
            "2          3  0.943925\n",
            "3          4  0.939252\n",
            "4          5  0.962617\n",
            "5          6  0.953271\n",
            "6          7  0.953271\n",
            "7          8  0.957944\n",
            "8          9  0.957944\n",
            "9         10  0.957944\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la tabla de resultados\n",
        "print(\"Resultados para criterion='gini' y splitter='best':\")\n",
        "print(results_gini_best)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYM3gy5hp1ix"
      },
      "source": [
        "**6. Repetir el procedimiento con criterion='entropy', splitter='best'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9TemwTAp45S",
        "outputId": "773eeb08-8c1e-4d11-9f36-fc357162e0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   max_depth  accuracy\n",
            "0          1  0.948598\n",
            "1          2  0.953271\n",
            "2          3  0.948598\n",
            "3          4  0.943925\n",
            "4          5  0.967290\n",
            "5          6  0.957944\n",
            "6          7  0.957944\n",
            "7          8  0.962617\n",
            "8          9  0.962617\n",
            "9         10  0.962617\n"
          ]
        }
      ],
      "source": [
        "# Evaluar árboles de decisión con criterion='entropy', splitter='best'\n",
        "results_entropy_best = evaluate_decision_trees('entropy', 'best', max_depth_values)\n",
        "print(results_entropy_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzkaXR7up7vc"
      },
      "source": [
        "**7. Incluir una tabla con el accuracy para los 10 árboles del punto anterior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8ePozfbqC6t",
        "outputId": "28633855-0d51-48ec-8f85-57aec55aa145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para criterion='entropy' y splitter='best':\n",
            "   max_depth  accuracy\n",
            "0          1  0.948598\n",
            "1          2  0.953271\n",
            "2          3  0.948598\n",
            "3          4  0.943925\n",
            "4          5  0.967290\n",
            "5          6  0.957944\n",
            "6          7  0.957944\n",
            "7          8  0.962617\n",
            "8          9  0.962617\n",
            "9         10  0.962617\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la tabla de resultados\n",
        "print(\"Resultados para criterion='entropy' y splitter='best':\")\n",
        "print(results_entropy_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL9ZmMj5qFyH"
      },
      "source": [
        "**8. Repetir el procedimiento con criterion='entropy', splitter='random'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nucCAAlqFCG",
        "outputId": "890763eb-c8bb-47fc-b95d-b93794c344b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   max_depth  accuracy\n",
            "0          1  0.813084\n",
            "1          2  0.813084\n",
            "2          3  0.925234\n",
            "3          4  0.845794\n",
            "4          5  0.855140\n",
            "5          6  0.929907\n",
            "6          7  0.864486\n",
            "7          8  0.948598\n",
            "8          9  0.934579\n",
            "9         10  0.939252\n"
          ]
        }
      ],
      "source": [
        "# Evaluar árboles de decisión con criterion='entropy', splitter='random'\n",
        "results_entropy_random = evaluate_decision_trees('entropy', 'random', max_depth_values)\n",
        "print(results_entropy_random)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFmg2JRjqOXa"
      },
      "source": [
        "**9. Incluir una tabla con el accuracy para los 10 árboles del punto anterior**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5BQVM2vqSV7",
        "outputId": "74e41980-2aaf-4405-ca2c-0fddff627484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para criterion='entropy' y splitter='random':\n",
            "   max_depth  accuracy\n",
            "0          1  0.813084\n",
            "1          2  0.813084\n",
            "2          3  0.925234\n",
            "3          4  0.845794\n",
            "4          5  0.855140\n",
            "5          6  0.929907\n",
            "6          7  0.864486\n",
            "7          8  0.948598\n",
            "8          9  0.934579\n",
            "9         10  0.939252\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la tabla de resultados\n",
        "print(\"Resultados para criterion='entropy' y splitter='random':\")\n",
        "print(results_entropy_random)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vF856yrqUhu"
      },
      "source": [
        "**10. Indicar los hiperparámetros que permiten obtener el árbol con mayor accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5N1rGdsqaib",
        "outputId": "bcabba5a-f923-4364-8d86-e65d47879a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor Modelo:\n",
            "Criterion: gini\n",
            "Splitter: best\n",
            "Max Depth: 5\n",
            "Accuracy: 4    0.962617\n",
            "4    0.967290\n",
            "4    0.855140\n",
            "Name: accuracy, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Combinar los resultados en un solo DataFrame\n",
        "all_results = pd.concat([\n",
        "    results_gini_best.assign(criterion='gini', splitter='best'),  # Agregamos los resultados con criterion='gini' y splitter='best'\n",
        "    results_entropy_best.assign(criterion='entropy', splitter='best'),  # Agregamos los resultados con criterion='entropy' y splitter='best'\n",
        "    results_entropy_random.assign(criterion='entropy', splitter='random')  # Agregamos los resultados con criterion='entropy' y splitter='random'\n",
        "])\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_tree_idx = all_results['accuracy'].idxmax()  # Encontramos el índice del modelo con la mayor precisión\n",
        "best_tree = all_results.loc[best_tree_idx]  # Extraemos los detalles del mejor modelo\n",
        "\n",
        "# Asegurarse de extraer correctamente los valores\n",
        "best_criterion = best_tree['criterion']  # Obtenemos el valor del criterio del mejor modelo\n",
        "best_splitter = best_tree['splitter']  # Obtenemos el valor del splitter del mejor modelo\n",
        "best_max_depth = best_tree['max_depth']  # Obtenemos el valor de la profundidad máxima del mejor modelo\n",
        "\n",
        "# Verificar tipos y convertir si es necesario\n",
        "if isinstance(best_criterion, pd.Series):\n",
        "    best_criterion = best_criterion.iloc[0]  # Si el valor es una serie, tomamos el primer elemento\n",
        "\n",
        "if isinstance(best_splitter, pd.Series):\n",
        "    best_splitter = best_splitter.iloc[0]  # Si el valor es una serie, tomamos el primer elemento\n",
        "\n",
        "if isinstance(best_max_depth, pd.Series):\n",
        "    best_max_depth = best_max_depth.iloc[0]  # Si el valor es una serie, tomamos el primer elemento\n",
        "\n",
        "# Convertir a entero si es necesario\n",
        "if isinstance(best_max_depth, float) and best_max_depth.is_integer():\n",
        "    best_max_depth = int(best_max_depth)  # Convertimos la profundidad máxima a entero si es un número entero\n",
        "\n",
        "# Imprimir el mejor modelo\n",
        "print(\"Mejor Modelo:\")\n",
        "print(f\"Criterion: {best_criterion}\")  # Imprimimos el criterio del mejor modelo\n",
        "print(f\"Splitter: {best_splitter}\")  # Imprimimos el splitter del mejor modelo\n",
        "print(f\"Max Depth: {best_max_depth}\")  # Imprimimos la profundidad máxima del mejor modelo\n",
        "print(f\"Accuracy: {best_tree['accuracy']}\")  # Imprimimos la precisión del mejor modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z94O6oPdqc0B"
      },
      "source": [
        "**11. Seleccionar otro hiperparámetro y realizar dos variaciones\n",
        "Se seleccionará el hiperparámetro min_samples_split.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aye43rIxqmxb",
        "outputId": "88a0269c-cb16-4d24-bdf1-25cd8f5093aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor Modelo:\n",
            "Criterion: gini\n",
            "Splitter: best\n",
            "Max Depth: 5\n",
            "Accuracy: 4    0.962617\n",
            "4    0.967290\n",
            "4    0.855140\n",
            "Name: accuracy, dtype: float64\n",
            "   min_samples_split  accuracy\n",
            "0                  2  0.962617\n",
            "1                 10  0.962617\n",
            "2                 20  0.962617\n",
            "Min Samples Split: 2\n",
            "Accuracy: 0.9626\n",
            "\n",
            "Min Samples Split: 10\n",
            "Accuracy: 0.9626\n",
            "\n",
            "Min Samples Split: 20\n",
            "Accuracy: 0.9626\n",
            "\n",
            "Análisis del impacto del hiperparámetro 'min_samples_split':\n",
            "Con min_samples_split=2, la precisión del modelo fue 0.9626.\n",
            "Con min_samples_split=10, la precisión del modelo fue 0.9626.\n",
            "Con min_samples_split=20, la precisión del modelo fue 0.9626.\n",
            "Comparando con el mejor accuracy anterior (0.9626):\n",
            "Min_samples_split=2 mantiene la precisión del modelo.\n",
            "Comparando con el mejor accuracy anterior (0.9626):\n",
            "Min_samples_split=10 mantiene la precisión del modelo.\n",
            "Comparando con el mejor accuracy anterior (0.9626):\n",
            "Min_samples_split=20 mantiene la precisión del modelo.\n"
          ]
        }
      ],
      "source": [
        "# Combinar los resultados en un solo DataFrame\n",
        "all_results = pd.concat([\n",
        "    results_gini_best.assign(criterion='gini', splitter='best'),\n",
        "    results_entropy_best.assign(criterion='entropy', splitter='best'),\n",
        "    results_entropy_random.assign(criterion='entropy', splitter='random')\n",
        "])\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_tree_idx = all_results['accuracy'].idxmax()\n",
        "best_tree = all_results.loc[best_tree_idx]\n",
        "\n",
        "# Asegurarse de extraer correctamente los valores\n",
        "best_criterion = best_tree['criterion']\n",
        "best_splitter = best_tree['splitter']\n",
        "best_max_depth = best_tree['max_depth']\n",
        "\n",
        "# Verificar tipos y convertir si es necesario\n",
        "if isinstance(best_criterion, pd.Series):\n",
        "    best_criterion = best_criterion.iloc[0]\n",
        "\n",
        "if isinstance(best_splitter, pd.Series):\n",
        "    best_splitter = best_splitter.iloc[0]\n",
        "\n",
        "if isinstance(best_max_depth, pd.Series):\n",
        "    best_max_depth = best_max_depth.iloc[0]\n",
        "\n",
        "# Convertir a entero si es necesario\n",
        "if isinstance(best_max_depth, float) and best_max_depth.is_integer():\n",
        "    best_max_depth = int(best_max_depth)\n",
        "\n",
        "print(\"Mejor Modelo:\")\n",
        "print(f\"Criterion: {best_criterion}\")\n",
        "print(f\"Splitter: {best_splitter}\")\n",
        "print(f\"Max Depth: {best_max_depth}\")\n",
        "print(f\"Accuracy: {best_tree['accuracy']}\")\n",
        "\n",
        "# Extraer correctamente el mejor accuracy\n",
        "best_accuracy_prev = best_tree['accuracy']\n",
        "if isinstance(best_accuracy_prev, pd.Series):\n",
        "    best_accuracy_prev = best_accuracy_prev.iloc[0]\n",
        "\n",
        "# Función para evaluar variaciones de min_samples_split\n",
        "def evaluate_min_samples_split(min_samples_split_values, criterion, splitter, max_depth, random_state=123):\n",
        "    results = []\n",
        "    for min_samples_split in min_samples_split_values:\n",
        "        clf = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_split=min_samples_split, random_state=random_state)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results.append({'min_samples_split': min_samples_split, 'accuracy': accuracy})\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Evaluar con las mejores configuraciones encontradas\n",
        "min_samples_split_values = [2, 10, 20]\n",
        "results_min_samples_split = evaluate_min_samples_split(min_samples_split_values, best_criterion, best_splitter, best_max_depth)\n",
        "print(results_min_samples_split)\n",
        "\n",
        "# Mostrar los resultados\n",
        "for result in results_min_samples_split.itertuples():\n",
        "    print(f\"Min Samples Split: {result.min_samples_split}\")\n",
        "    print(f\"Accuracy: {result.accuracy:.4f}\\n\")\n",
        "\n",
        "# Análisis final\n",
        "print(\"Análisis del impacto del hiperparámetro 'min_samples_split':\")\n",
        "for result in results_min_samples_split.itertuples():\n",
        "    print(f\"Con min_samples_split={result.min_samples_split}, la precisión del modelo fue {result.accuracy:.4f}.\")\n",
        "\n",
        "# Comparación con el mejor accuracy obtenido anteriormente\n",
        "for result in results_min_samples_split.itertuples():\n",
        "    print(f\"Comparando con el mejor accuracy anterior ({best_accuracy_prev:.4f}):\")\n",
        "    if result.accuracy > best_accuracy_prev:\n",
        "        print(f\"Min_samples_split={result.min_samples_split} mejora la precisión del modelo.\")\n",
        "    elif result.accuracy < best_accuracy_prev:\n",
        "        print(f\"Min_samples_split={result.min_samples_split} empeora la precisión del modelo.\")\n",
        "    else:\n",
        "        print(f\"Min_samples_split={result.min_samples_split} mantiene la precisión del modelo.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
